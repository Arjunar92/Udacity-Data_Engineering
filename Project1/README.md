**Data Modeling with Postgres

***Introduction

Sparkfy, a new online music streaming app platform wants to analyze their user activity in their music app. Currently the data is not in a form that can be easily queried for information. 
They would like a Data Engineer to suggest them on possible solutions,create database schemas and build an ETL pipeline. 

***Project objective:

Use Postgres database to build a ETL pipeline using Python. Define fact and Diemsion tables, implement a star schema. the data needs to be extracted from the two JSOn files, transformed using pipelines and then ultimately load to the database. 


* File info:

data:

song_data: Each file is in JSON format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID. For example, here are file paths to two files in this dataset.

log_data:  This consists of log files in JSON format generated by this event simulator based on the songs in the dataset above. These simulate activity logs from a music streaming app based on specified configurations.

etl.py: 
Extract data from song_data and log_data and load them to a database. 

sql_queries.py:
Has helper SQl query statements to CREATE, INSERT, SELECT, DROP tables, for etl.py and create_tables.py

create_tables.py:
Run this file to create Fact and Dimensions table. 

create_database: This function helps in droping existing database, create new database and return the connection.

drop_tables: Used to drop the existing tables.

create_tables: This helps in creating above mentioned fact table and dimension tables.

